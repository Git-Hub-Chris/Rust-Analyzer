//! `tt` crate defines a `TokenTree` data structure: this is the interface (both
//! input and output) of macros. It closely mirrors `proc_macro` crate's
//! `TokenTree`.

#![cfg_attr(feature = "in-rust-tree", feature(rustc_private))]

#[cfg(not(feature = "in-rust-tree"))]
extern crate ra_ap_rustc_lexer as rustc_lexer;
#[cfg(feature = "in-rust-tree")]
extern crate rustc_lexer;

// pub mod buffer;
// pub mod iter;

use std::{fmt, mem};

use intern::Symbol;
use stdx::itertools::Itertools as _;

pub use text_size::{TextRange, TextSize};

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Token<Span> {
    pub kind: TokenKind,
    pub span: Span,
}

impl<Span> Token<Span> {
    pub fn new(kind: TokenKind, span: Span) -> Self {
        Token { kind, span }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum CommentKind {
    Line,
    Block,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum BinOpToken {
    Plus,
    Minus,
    Star,
    Slash,
    Percent,
    Caret,
    And,
    Or,
    Shl,
    Shr,
}

/// Describes how a sequence of token trees is delimited.
/// Cannot use `proc_macro::Delimiter` directly because this
/// structure should implement some additional traits.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum Delimiter {
    /// `( ... )`
    Parenthesis,
    /// `{ ... }`
    Brace,
    /// `[ ... ]`
    Bracket,
    /// `∅ ... ∅`
    /// An invisible delimiter, that may, for example, appear around tokens coming from a
    /// "macro variable" `$var`. It is important to preserve operator priorities in cases like
    /// `$var * 3` where `$var` is `1 + 2`.
    /// Invisible delimiters might not survive roundtrip of a token stream through a string.
    Invisible,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum LitKind {
    Byte,
    Char,
    Integer, // e.g. `1`, `1u8`, `1f32`
    Float,   // e.g. `1.`, `1.0`, `1e3f32`
    Str,
    StrRaw(u8), // raw string delimited by `n` hash symbols
    ByteStr,
    ByteStrRaw(u8), // raw byte string delimited by `n` hash symbols
    CStr,
    CStrRaw(u8),
    Err(()),
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum AttrStyle {
    Outer,
    Inner,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub enum IdentIsRaw {
    No,
    Yes,
}

impl IdentIsRaw {
    pub fn yes(self) -> bool {
        matches!(self, IdentIsRaw::Yes)
    }
    pub fn no(&self) -> bool {
        matches!(self, IdentIsRaw::No)
    }
    pub fn as_str(self) -> &'static str {
        match self {
            IdentIsRaw::No => "",
            IdentIsRaw::Yes => "r#",
        }
    }
    pub fn split_from_symbol(sym: &str) -> (Self, &str) {
        if let Some(sym) = sym.strip_prefix("r#") {
            (IdentIsRaw::Yes, sym)
        } else {
            (IdentIsRaw::No, sym)
        }
    }
}

impl From<bool> for IdentIsRaw {
    fn from(b: bool) -> Self {
        match b {
            true => Self::Yes,
            false => Self::No,
        }
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum TokenKind {
    /* Expression-operator symbols. */
    /// `=`
    Eq,
    /// `<`
    Lt,
    /// `<=`
    Le,
    /// `==`
    EqEq,
    /// `!=`
    Ne,
    /// `>=`
    Ge,
    /// `>`
    Gt,
    /// `&&`
    AndAnd,
    /// `||`
    OrOr,
    /// `!`
    Not,
    /// `~`
    Tilde,
    BinOp(BinOpToken),
    BinOpEq(BinOpToken),

    /* Structural symbols */
    /// `@`
    At,
    /// `.`
    Dot,
    /// `..`
    DotDot,
    /// `...`
    DotDotDot,
    /// `..=`
    DotDotEq,
    /// `,`
    Comma,
    /// `;`
    Semi,
    /// `:`
    Colon,
    /// `::`
    PathSep,
    /// `->`
    RArrow,
    /// `<-`
    LArrow,
    /// `=>`
    FatArrow,
    /// `#`
    Pound,
    /// `$`
    Dollar,
    /// `?`
    Question,
    /// Used by proc macros for representing lifetimes, not generated by lexer right now.
    SingleQuote,
    /// An opening delimiter (e.g., `{`).
    OpenDelim(Delimiter),
    /// A closing delimiter (e.g., `}`).
    CloseDelim(Delimiter),

    /* Literals */
    // The box shrinks this enum by 8 bytes
    Literal(Box<Literal>),

    /// Identifier token.
    Ident(Symbol, IdentIsRaw),

    /// Lifetime identifier token.
    Lifetime(Symbol),

    /// A doc comment token.
    /// `Symbol` is the doc comment's data excluding its "quotes" (`///`, `/**`, etc)
    /// similarly to symbols in string literal tokens.
    DocComment(CommentKind, AttrStyle, Symbol),

    /// End Of File
    Eof,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct TokenStream<Span>(pub Box<[TokenTree<Span>]>);

impl<S> TokenStream<S> {
    pub fn trees(&self) -> RefTokenTreeCursor<'_, S> {
        RefTokenTreeCursor::new(self)
    }

    pub fn into_trees(self) -> TokenTreeCursor<S> {
        TokenTreeCursor::new(self)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum TokenTree<Span> {
    /// A single token. Should never be `OpenDelim` or `CloseDelim`, because
    /// delimiters are implicitly represented by `Delimited`.
    Token(Token<Span>, Spacing),
    /// A delimited sequence of token trees.
    Delimited(DelimSpan<Span>, DelimSpacing, Delimiter, TokenStream<Span>),
}

impl<S: Copy> TokenTree<S> {
    pub fn empty(span: S) -> Self {
        Self::Delimited(
            DelimSpan::from_single(span),
            DelimSpacing { open: Spacing::Alone, close: Spacing::Alone },
            Delimiter::Invisible,
            TokenStream(Box::new([])),
        )
    }

    pub fn first_span(&self) -> S {
        match self {
            TokenTree::Token(t, _) => t.span,
            TokenTree::Delimited(s, ..) => s.open,
        }
    }
}

#[derive(Debug, Copy, Clone, PartialEq, Eq, Hash)]
pub struct DelimSpan<S> {
    pub open: S,
    pub close: S,
}

impl<Span: Copy> DelimSpan<Span> {
    pub fn from_single(sp: Span) -> Self {
        DelimSpan { open: sp, close: sp }
    }

    pub fn from_pair(open: Span, close: Span) -> Self {
        DelimSpan { open, close }
    }

    pub fn entire(self) -> Span
    where
        Span: SpanOps,
    {
        self.open.up_to(self.close)
    }
}

pub trait SpanOps {
    fn up_to(self, other: Self) -> Self;
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct Literal {
    // escaped
    pub symbol: Symbol,
    pub kind: LitKind,
    pub suffix: Option<Symbol>,
}

pub fn token_to_literal(text: &str) -> Literal {
    use rustc_lexer::LiteralKind;

    let token = rustc_lexer::tokenize(text).next_tuple();
    let Some((rustc_lexer::Token {
        kind: rustc_lexer::TokenKind::Literal { kind, suffix_start },
        ..
    },)) = token
    else {
        return Literal { symbol: Symbol::intern(text), kind: LitKind::Err(()), suffix: None };
    };

    let (kind, start_offset, end_offset) = match kind {
        LiteralKind::Int { .. } => (LitKind::Integer, 0, 0),
        LiteralKind::Float { .. } => (LitKind::Float, 0, 0),
        LiteralKind::Char { terminated } => (LitKind::Char, 1, terminated as usize),
        LiteralKind::Byte { terminated } => (LitKind::Byte, 2, terminated as usize),
        LiteralKind::Str { terminated } => (LitKind::Str, 1, terminated as usize),
        LiteralKind::ByteStr { terminated } => (LitKind::ByteStr, 2, terminated as usize),
        LiteralKind::CStr { terminated } => (LitKind::CStr, 2, terminated as usize),
        LiteralKind::RawStr { n_hashes } => (
            LitKind::StrRaw(n_hashes.unwrap_or_default()),
            2 + n_hashes.unwrap_or_default() as usize,
            1 + n_hashes.unwrap_or_default() as usize,
        ),
        LiteralKind::RawByteStr { n_hashes } => (
            LitKind::ByteStrRaw(n_hashes.unwrap_or_default()),
            3 + n_hashes.unwrap_or_default() as usize,
            1 + n_hashes.unwrap_or_default() as usize,
        ),
        LiteralKind::RawCStr { n_hashes } => (
            LitKind::CStrRaw(n_hashes.unwrap_or_default()),
            3 + n_hashes.unwrap_or_default() as usize,
            1 + n_hashes.unwrap_or_default() as usize,
        ),
    };

    let (lit, suffix) = text.split_at(suffix_start as usize);
    let lit = &lit[start_offset..lit.len() - end_offset];
    let suffix = match suffix {
        "" | "_" => None,
        suffix => Some(Symbol::intern(suffix)),
    };

    Literal { symbol: Symbol::intern(lit), kind, suffix }
}

/// Indicates whether a token can join with the following token to form a
/// compound token. Used for conversions to `proc_macro::Spacing`. Also used to
/// guide pretty-printing, which is where the `JointHidden` value (which isn't
/// part of `proc_macro::Spacing`) comes in useful.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Spacing {
    /// The token cannot join with the following token to form a compound
    /// token.
    ///
    /// In token streams parsed from source code, the compiler will use `Alone`
    /// for any token immediately followed by whitespace, a non-doc comment, or
    /// EOF.
    ///
    /// When constructing token streams within the compiler, use this for each
    /// token that (a) should be pretty-printed with a space after it, or (b)
    /// is the last token in the stream. (In the latter case the choice of
    /// spacing doesn't matter because it is never used for the last token. We
    /// arbitrarily use `Alone`.)
    ///
    /// Converts to `proc_macro::Spacing::Alone`, and
    /// `proc_macro::Spacing::Alone` converts back to this.
    Alone,

    /// The token can join with the following token to form a compound token.
    ///
    /// In token streams parsed from source code, the compiler will use `Joint`
    /// for any token immediately followed by punctuation (as determined by
    /// `Token::is_punct`).
    ///
    /// When constructing token streams within the compiler, use this for each
    /// token that (a) should be pretty-printed without a space after it, and
    /// (b) is followed by a punctuation token.
    ///
    /// Converts to `proc_macro::Spacing::Joint`, and
    /// `proc_macro::Spacing::Joint` converts back to this.
    Joint,

    /// The token can join with the following token to form a compound token,
    /// but this will not be visible at the proc macro level. (This is what the
    /// `Hidden` means; see below.)
    ///
    /// In token streams parsed from source code, the compiler will use
    /// `JointHidden` for any token immediately followed by anything not
    /// covered by the `Alone` and `Joint` cases: an identifier, lifetime,
    /// literal, delimiter, doc comment.
    ///
    /// When constructing token streams, use this for each token that (a)
    /// should be pretty-printed without a space after it, and (b) is followed
    /// by a non-punctuation token.
    ///
    /// Converts to `proc_macro::Spacing::Alone`, but
    /// `proc_macro::Spacing::Alone` converts back to `token::Spacing::Alone`.
    /// Because of that, pretty-printing of `TokenStream`s produced by proc
    /// macros is unavoidably uglier (with more whitespace between tokens) than
    /// pretty-printing of `TokenStream`'s produced by other means (i.e. parsed
    /// source code, internally constructed token streams, and token streams
    /// produced by declarative macros).
    JointHidden,
}

#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]
pub struct DelimSpacing {
    pub open: Spacing,
    pub close: Spacing,
}

impl DelimSpacing {
    pub fn new(open: Spacing, close: Spacing) -> DelimSpacing {
        DelimSpacing { open, close }
    }
}

impl fmt::Display for Literal {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self.kind {
            LitKind::Byte => write!(f, "b'{}'", self.symbol),
            LitKind::Char => write!(f, "'{}'", self.symbol),
            LitKind::Integer | LitKind::Float | LitKind::Err(_) => write!(f, "{}", self.symbol),
            LitKind::Str => write!(f, "\"{}\"", self.symbol),
            LitKind::ByteStr => write!(f, "b\"{}\"", self.symbol),
            LitKind::CStr => write!(f, "c\"{}\"", self.symbol),
            LitKind::StrRaw(num_of_hashes) => {
                let num_of_hashes = num_of_hashes as usize;
                write!(
                    f,
                    r#"r{0:#<num_of_hashes$}"{text}"{0:#<num_of_hashes$}"#,
                    "",
                    text = self.symbol
                )
            }
            LitKind::ByteStrRaw(num_of_hashes) => {
                let num_of_hashes = num_of_hashes as usize;
                write!(
                    f,
                    r#"br{0:#<num_of_hashes$}"{text}"{0:#<num_of_hashes$}"#,
                    "",
                    text = self.symbol
                )
            }
            LitKind::CStrRaw(num_of_hashes) => {
                let num_of_hashes = num_of_hashes as usize;
                write!(
                    f,
                    r#"cr{0:#<num_of_hashes$}"{text}"{0:#<num_of_hashes$}"#,
                    "",
                    text = self.symbol
                )
            }
        }?;
        if let Some(suffix) = &self.suffix {
            write!(f, "{}", suffix)?;
        }
        Ok(())
    }
}
// fn print_debug_subtree<S: fmt::Debug>(
//     f: &mut fmt::Formatter<'_>,
//     subtree: &Subtree<S>,
//     level: usize,
// ) -> fmt::Result {
//     let align = "  ".repeat(level);

//     let Delimiter { kind, open, close } = &subtree.delimiter;
//     let delim = match kind {
//         DelimiterKind::Invisible => "$$",
//         DelimiterKind::Parenthesis => "()",
//         DelimiterKind::Brace => "{}",
//         DelimiterKind::Bracket => "[]",
//     };

//     write!(f, "{align}SUBTREE {delim} ",)?;
//     fmt::Debug::fmt(&open, f)?;
//     write!(f, " ")?;
//     fmt::Debug::fmt(&close, f)?;
//     if !subtree.token_trees.is_empty() {
//         writeln!(f)?;
//         for (idx, child) in subtree.token_trees.iter().enumerate() {
//             print_debug_token(f, child, level + 1)?;
//             if idx != subtree.token_trees.len() - 1 {
//                 writeln!(f)?;
//             }
//         }
//     }

//     Ok(())
// }

// fn print_debug_token<S: fmt::Debug>(
//     f: &mut fmt::Formatter<'_>,
//     tkn: &TokenTree<S>,
//     level: usize,
// ) -> fmt::Result {
//     let align = "  ".repeat(level);

//     match tkn {
//         TokenTree::Leaf(leaf) => match leaf {
//             Leaf::Literal(lit) => {
//                 write!(
//                     f,
//                     "{}LITERAL {:?} {}{} {:#?}",
//                     align,
//                     lit.kind,
//                     lit.symbol,
//                     lit.suffix.as_ref().map(|it| it.as_str()).unwrap_or(""),
//                     lit.span
//                 )?;
//             }
//             Leaf::Punct(punct) => {
//                 write!(
//                     f,
//                     "{}PUNCH   {} [{}] {:#?}",
//                     align,
//                     punct.char,
//                     if punct.spacing == Spacing::Alone { "alone" } else { "joint" },
//                     punct.span
//                 )?;
//             }
//             Leaf::Ident(ident) => {
//                 write!(
//                     f,
//                     "{}IDENT   {}{} {:#?}",
//                     align,
//                     ident.is_raw.as_str(),
//                     ident.sym,
//                     ident.span
//                 )?;
//             }
//         },
//         TokenTree::Subtree(subtree) => {
//             print_debug_subtree(f, subtree, level)?;
//         }
//     }

//     Ok(())
// }

// impl<S> fmt::Display for Subtree<S> {
//     fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
//         let (l, r) = match self.delimiter.kind {
//             DelimiterKind::Parenthesis => ("(", ")"),
//             DelimiterKind::Brace => ("{", "}"),
//             DelimiterKind::Bracket => ("[", "]"),
//             DelimiterKind::Invisible => ("", ""),
//         };
//         f.write_str(l)?;
//         let mut needs_space = false;
//         for tt in self.token_trees.iter() {
//             if needs_space {
//                 f.write_str(" ")?;
//             }
//             needs_space = true;
//             match tt {
//                 TokenTree::Leaf(Leaf::Punct(p)) => {
//                     needs_space = p.spacing == Spacing::Alone;
//                     fmt::Display::fmt(p, f)?;
//                 }
//                 tt => fmt::Display::fmt(tt, f)?,
//             }
//         }
//         f.write_str(r)?;
//         Ok(())
//     }
// }

// impl<S> Subtree<S> {
//     /// Count the number of tokens recursively
//     pub fn count(&self) -> usize {
//         let children_count = self
//             .token_trees
//             .iter()
//             .map(|c| match c {
//                 TokenTree::Subtree(c) => c.count(),
//                 TokenTree::Leaf(_) => 0,
//             })
//             .sum::<usize>();

//         self.token_trees.len() + children_count
//     }
// }

// impl<S> Subtree<S> {
//     /// A simple line string used for debugging
//     pub fn as_debug_string(&self) -> String {
//         let delim = match self.delimiter.kind {
//             DelimiterKind::Brace => ("{", "}"),
//             DelimiterKind::Bracket => ("[", "]"),
//             DelimiterKind::Parenthesis => ("(", ")"),
//             DelimiterKind::Invisible => ("$", "$"),
//         };

//         let mut res = String::new();
//         res.push_str(delim.0);
//         let mut last = None;
//         for child in self.token_trees.iter() {
//             let s = match child {
//                 TokenTree::Leaf(it) => {
//                     let s = match it {
//                         Leaf::Literal(it) => it.symbol.to_string(),
//                         Leaf::Punct(it) => it.char.to_string(),
//                         Leaf::Ident(it) => format!("{}{}", it.is_raw.as_str(), it.sym),
//                     };
//                     match (it, last) {
//                         (Leaf::Ident(_), Some(&TokenTree::Leaf(Leaf::Ident(_)))) => {
//                             " ".to_owned() + &s
//                         }
//                         (Leaf::Punct(_), Some(TokenTree::Leaf(Leaf::Punct(punct)))) => {
//                             if punct.spacing == Spacing::Alone {
//                                 " ".to_owned() + &s
//                             } else {
//                                 s
//                             }
//                         }
//                         _ => s,
//                     }
//                 }
//                 TokenTree::Subtree(it) => it.as_debug_string(),
//             };
//             res.push_str(&s);
//             last = Some(child);
//         }

//         res.push_str(delim.1);
//         res
//     }
// }

// pub fn pretty<S>(tkns: &[TokenTree<S>]) -> String {
//     fn tokentree_to_text<S>(tkn: &TokenTree<S>) -> String {
//         match tkn {
//             TokenTree::Leaf(Leaf::Ident(ident)) => {
//                 format!("{}{}", ident.is_raw.as_str(), ident.sym)
//             }
//             TokenTree::Leaf(Leaf::Literal(literal)) => format!("{literal}"),
//             TokenTree::Leaf(Leaf::Punct(punct)) => format!("{}", punct.char),
//             TokenTree::Subtree(subtree) => {
//                 let content = pretty(&subtree.token_trees);
//                 let (open, close) = match subtree.delimiter.kind {
//                     DelimiterKind::Brace => ("{", "}"),
//                     DelimiterKind::Bracket => ("[", "]"),
//                     DelimiterKind::Parenthesis => ("(", ")"),
//                     DelimiterKind::Invisible => ("", ""),
//                 };
//                 format!("{open}{content}{close}")
//             }
//         }
//     }

//     tkns.iter()
//         .fold((String::new(), true), |(last, last_to_joint), tkn| {
//             let s = [last, tokentree_to_text(tkn)].join(if last_to_joint { "" } else { " " });
//             let mut is_joint = false;
//             if let TokenTree::Leaf(Leaf::Punct(punct)) = tkn {
//                 if punct.spacing == Spacing::Joint {
//                     is_joint = true;
//                 }
//             }
//             (s, is_joint)
//         })
//         .0
// }
/// By-reference iterator over a [`TokenStream`], that produces `&TokenTree`
/// items.
#[derive(Clone, Debug)]
pub struct RefTokenTreeCursor<'t, S> {
    stream: &'t TokenStream<S>,
    index: usize,
}

impl<'t, S> RefTokenTreeCursor<'t, S> {
    fn new(stream: &'t TokenStream<S>) -> Self {
        RefTokenTreeCursor { stream, index: 0 }
    }

    pub fn look_ahead(&self, n: usize) -> Option<&TokenTree<S>> {
        self.stream.0.get(self.index + n)
    }
}

impl<'t, S> Iterator for RefTokenTreeCursor<'t, S> {
    type Item = &'t TokenTree<S>;

    fn next(&mut self) -> Option<&'t TokenTree<S>> {
        self.stream.0.get(self.index).inspect(|_| self.index += 1)
    }
}

/// Owning by-value iterator over a [`TokenStream`], that produces `&TokenTree`
/// items.
///
/// Doesn't impl `Iterator` because Rust doesn't permit an owning iterator to
/// return `&T` from `next`; the need for an explicit lifetime in the `Item`
/// associated type gets in the way. Instead, use `next_ref` (which doesn't
/// involve associated types) for getting individual elements, or
/// `RefTokenTreeCursor` if you really want an `Iterator`, e.g. in a `for`
/// loop.
#[derive(Clone, Debug)]
pub struct TokenTreeCursor<S> {
    pub stream: TokenStream<S>,
    index: usize,
}

impl<S> TokenTreeCursor<S> {
    fn new(stream: TokenStream<S>) -> Self {
        TokenTreeCursor { stream, index: 0 }
    }

    #[inline]
    pub fn next_ref(&mut self) -> Option<&TokenTree<S>> {
        self.stream.0.get(self.index).inspect(|_| self.index += 1)
    }

    pub fn look_ahead(&self, n: usize) -> Option<&TokenTree<S>> {
        self.stream.0.get(self.index + n)
    }
}

#[derive(Clone, Debug)]
pub struct TokenCursor<S> {
    // Cursor for the current (innermost) token stream. The delimiters for this
    // token stream are found in `self.stack.last()`; when that is `None` then
    // we are in the outermost token stream which never has delimiters.
    tree_cursor: TokenTreeCursor<S>,

    // Token streams surrounding the current one. The delimiters for stack[n]'s
    // tokens are in `stack[n-1]`. `stack[0]` (when present) has no delimiters
    // because it's the outermost token stream which never has delimiters.
    stack: Vec<(TokenTreeCursor<S>, DelimSpan<S>, DelimSpacing, Delimiter)>,
}

impl<S: Copy> TokenCursor<S> {
    pub fn new(stream: TokenStream<S>) -> Self {
        TokenCursor { tree_cursor: TokenTreeCursor::new(stream), stack: Vec::new() }
    }

    #[allow(clippy::should_implement_trait)]
    pub fn next(&mut self) -> Option<(Token<S>, Spacing)> {
        self.inlined_next()
    }

    /// This always-inlined version should only be used on hot code paths.
    #[inline(always)]
    pub fn inlined_next(&mut self) -> Option<(Token<S>, Spacing)> {
        loop {
            // FIXME: we currently don't return `Delimiter::Invisible` open/close delims. To fix
            // #67062 we will need to, whereupon the `delim != Delimiter::Invisible` conditions
            // below can be removed.
            if let Some(tree) = self.tree_cursor.next_ref() {
                match *tree {
                    TokenTree::Token(ref token, spacing) => {
                        debug_assert!(!matches!(
                            token.kind,
                            TokenKind::OpenDelim(_) | TokenKind::CloseDelim(_)
                        ));
                        return Some((token.clone(), spacing));
                    }
                    TokenTree::Delimited(sp, spacing, delim, ref tts) => {
                        let trees = tts.clone().into_trees();
                        self.stack.push((
                            mem::replace(&mut self.tree_cursor, trees),
                            sp,
                            spacing,
                            delim,
                        ));
                        if delim != Delimiter::Invisible {
                            return Some((
                                Token::new(TokenKind::OpenDelim(delim), sp.open),
                                spacing.open,
                            ));
                        }
                        // No open delimiter to return; continue on to the next iteration.
                    }
                };
            } else if let Some((tree_cursor, span, spacing, delim)) = self.stack.pop() {
                // We have exhausted this token stream. Move back to its parent token stream.
                self.tree_cursor = tree_cursor;
                if delim != Delimiter::Invisible {
                    return Some((
                        Token::new(TokenKind::CloseDelim(delim), span.close),
                        spacing.close,
                    ));
                }
                // No close delimiter to return; continue on to the next iteration.
            } else {
                return None;
            }
        }
    }
}

#[derive(Clone, Debug)]
pub struct RefTokenCursor<'a, S> {
    // Cursor for the current (innermost) token stream. The delimiters for this
    // token stream are found in `self.stack.last()`; when that is `None` then
    // we are in the outermost token stream which never has delimiters.
    tree_cursor: RefTokenTreeCursor<'a, S>,

    // Token streams surrounding the current one. The delimiters for stack[n]'s
    // tokens are in `stack[n-1]`. `stack[0]` (when present) has no delimiters
    // because it's the outermost token stream which never has delimiters.
    stack: Vec<(RefTokenTreeCursor<'a, S>, DelimSpan<S>, DelimSpacing, Delimiter)>,
}

impl<'a, S: Copy> RefTokenCursor<'a, S> {
    pub fn new(stream: &'a TokenStream<S>) -> Self {
        RefTokenCursor { tree_cursor: RefTokenTreeCursor::new(stream), stack: Vec::new() }
    }

    #[allow(clippy::should_implement_trait)]
    pub fn next(&mut self) -> Option<(Token<S>, Spacing)> {
        self.inlined_next()
    }

    pub fn at_root(&self) -> bool {
        self.stack.is_empty()
    }

    /// This always-inlined version should only be used on hot code paths.
    #[inline(always)]
    pub fn inlined_next(&mut self) -> Option<(Token<S>, Spacing)> {
        loop {
            // FIXME: we currently don't return `Delimiter::Invisible` open/close delims. To fix
            // #67062 we will need to, whereupon the `delim != Delimiter::Invisible` conditions
            // below can be removed.
            if let Some(tree) = self.tree_cursor.next() {
                match *tree {
                    TokenTree::Token(ref token, spacing) => {
                        debug_assert!(!matches!(
                            token.kind,
                            TokenKind::OpenDelim(_) | TokenKind::CloseDelim(_)
                        ));
                        return Some((token.clone(), spacing));
                    }
                    TokenTree::Delimited(sp, spacing, delim, ref tts) => {
                        let trees = tts.trees();
                        self.stack.push((
                            mem::replace(&mut self.tree_cursor, trees),
                            sp,
                            spacing,
                            delim,
                        ));
                        if delim != Delimiter::Invisible {
                            return Some((
                                Token::new(TokenKind::OpenDelim(delim), sp.open),
                                spacing.open,
                            ));
                        }
                        // No open delimiter to return; continue on to the next iteration.
                    }
                };
            } else if let Some((tree_cursor, span, spacing, delim)) = self.stack.pop() {
                // We have exhausted this token stream. Move back to its parent token stream.
                self.tree_cursor = tree_cursor;
                if delim != Delimiter::Invisible {
                    return Some((
                        Token::new(TokenKind::CloseDelim(delim), span.close),
                        spacing.close,
                    ));
                }
                // No close delimiter to return; continue on to the next iteration.
            } else {
                return None;
            }
        }
    }
}
